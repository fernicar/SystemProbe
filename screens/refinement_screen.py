from PySide6.QtWidgets import (QVBoxLayout, QLabel, QTextBrowser, QPushButton, QWidget,
                               QHBoxLayout, QTextEdit, QMessageBox, QSizePolicy, QGroupBox)
from PySide6.QtCore import Qt, Slot
from .base_screen import BaseScreen
from workers import Worker

class RefinementScreen(BaseScreen):
    def __init__(self, main_window, state_manager, settings_manager, llm_handler):
        super().__init__(main_window, state_manager, settings_manager, llm_handler)
        self.worker = None
        self.suggested_prompt = "" # Store the suggested prompt from LLM A
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)

        title = QLabel("Step 4: Analyze and Refine")
        title_font = title.font()
        title_font.setPointSize(16)
        title_font.setBold(True)
        title.setFont(title_font)
        layout.addWidget(title)

        # --- Refiner Output Group ---
        refiner_group = QGroupBox("Refiner LLM (A) Analysis")
        refiner_layout = QVBoxLayout(refiner_group)

        self.analysis_browser = QTextBrowser()
        self.analysis_browser.setPlaceholderText("Generating analysis and suggested prompt from Refiner LLM (A)...")
        self.analysis_browser.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        refiner_layout.addWidget(self.analysis_browser)

        layout.addWidget(refiner_group)
        # --- End Refiner Output Group ---

        # --- User Guidance Group ---
        guidance_group = QGroupBox("Optional Guidance for Refinement")
        guidance_layout = QVBoxLayout(guidance_group)

        guidance_label = QLabel("Provide specific feedback for the Refiner LLM (e.g., 'be more concise', 'focus on JSON output'). This will be used immediately when clicking 'Refine Prompt' button. You can reroll results multiple times before proceeding to test.")
        guidance_label.setWordWrap(True)
        guidance_layout.addWidget(guidance_label)

        self.guidance_edit = QTextEdit()
        self.guidance_edit.setPlaceholderText("Optional: Enter feedback here...")
        self.guidance_edit.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.MinimumExpanding)
        self.guidance_edit.setMaximumHeight(150) # Limit height
        guidance_layout.addWidget(self.guidance_edit)

        layout.addWidget(guidance_group)
        # --- End User Guidance Group ---

        layout.setStretchFactor(refiner_group, 2) # Give more space to analysis
        layout.setStretchFactor(guidance_group, 1)

        nav_layout = QHBoxLayout()
        self.back_button = QPushButton("Back (View Last Output)")
        self.back_button.setToolTip("Return to the previous screen showing the output generated by LLM B.")
        self.back_button.clicked.connect(lambda: self.main_window.navigate_to("output_testing"))

        self.refine_button = QPushButton("Refine Prompt")
        self.refine_button.setToolTip("Use current guidance to generate a new suggestion from Refiner LLM (A). You can click this multiple times to reroll results.")
        self.refine_button.clicked.connect(self.run_refiner_llm)

        self.test_refined_button = QPushButton("Test Refined Prompt")
        self.test_refined_button.setToolTip("When satisfied with the current suggestion, use it to run LLM B again.")
        self.test_refined_button.clicked.connect(self.test_refined_prompt)

        self.accept_suggested_button = QPushButton("Accept Current Suggested Prompt")
        self.accept_suggested_button.setToolTip("Accept the prompt suggested below without further testing.")
        self.accept_suggested_button.clicked.connect(self.accept_suggested_prompt)


        nav_layout.addWidget(self.back_button)
        nav_layout.addStretch(1)
        nav_layout.addWidget(self.refine_button)
        nav_layout.addWidget(self.test_refined_button)
        nav_layout.addWidget(self.accept_suggested_button)

        layout.addLayout(nav_layout)
        self.setLayout(layout)

        self.set_buttons_enabled(False) # Disabled until LLM A completes


    def set_buttons_enabled(self, enabled):
        self.back_button.setEnabled(enabled)
        self.refine_button.setEnabled(enabled)
        self.test_refined_button.setEnabled(enabled)
        self.accept_suggested_button.setEnabled(enabled)
        self.guidance_edit.setEnabled(enabled)


    def enter_screen(self):
        super().enter_screen() # Calls load_state
        self.state_manager.set_current_step("refinement")
        # Trigger LLM A (Refiner) call
        self.run_refiner_llm()

    def load_state(self):
        # Load optional guidance from state
        self.guidance_edit.setPlainText(self.state_manager.get_optional_guidance())
        # Clear previous analysis and suggested prompt
        self.analysis_browser.setPlaceholderText("Generating analysis and suggested prompt...")
        self.analysis_browser.clear()
        self.suggested_prompt = ""

    def save_state(self):
        # Save the optional guidance text
        self.state_manager.set_optional_guidance(self.guidance_edit.toPlainText())
        # The 'currentSystemPrompt' is updated only when 'Test Refined Prompt' is clicked


    def run_refiner_llm(self):
         # Check for API key before proceeding
        if not self.settings_manager.get_groq_api_key():
            self.show_error("API Key Missing", "Groq API key not configured. Cannot run Refiner LLM.")
            self.analysis_browser.setPlaceholderText("API Key Missing. Cannot generate refinement.")
            self.set_buttons_enabled(True) # Allow back navigation
            self.back_button.setEnabled(True)
            self.refine_button.setEnabled(False) # Can't refine without guidance
            self.test_refined_button.setEnabled(False)
            self.accept_suggested_button.setEnabled(False)
            return

        self.analysis_browser.setPlaceholderText("Generating analysis and suggested prompt from Refiner LLM (A)...")
        self.update_status("Refiner LLM (A): Analyzing and generating suggestion...")
        self.set_buttons_enabled(False)

        # --- Prepare Context for LLM A ---
        state = self.state_manager.get_state()
        # Use the current guidance from the text field instead of from state
        current_guidance = self.guidance_edit.toPlainText().strip()

        context_data = {
            "userInputExamples": state.get("userInputExamples", []),
            "desiredOutputExamples": state.get("desiredOutputExamples", []),
            "last_prompt": state.get("currentSystemPrompt", ""), # The prompt that was just tested
            "last_output": state.get("lastTesterOutput", ""),
            "last_score": state.get("lastScore", None),
            "user_feedback": current_guidance, # Use current guidance from the text field
            "prompt_history": state.get("promptHistory", [])
        }

        # --- Setup Worker Thread ---
        self.worker = Worker(self.llm_handler.run_refiner_llm, context_data)
        self.worker.signals.result.connect(self.handle_refiner_result)
        self.worker.signals.error.connect(self.handle_llm_error)
        self.worker.signals.finished.connect(self.on_worker_finished)
        self.worker.signals.status.connect(self.update_status)
        self.worker.start()
        # --- End Worker Setup ---

    @Slot(object)
    def handle_refiner_result(self, result_data):
        analysis = result_data.get("analysis", "Analysis not found.")
        self.suggested_prompt = result_data.get("suggested_prompt", "Suggested prompt not found.")

        # Display in the browser
        display_text = f"--- Analysis ---\n{analysis}\n\n--- Suggested New System Prompt ---\n{self.suggested_prompt}"
        self.analysis_browser.setPlainText(display_text)

        # Store the analysis in history when moving forward
        # We don't save the suggested prompt to state *yet*, only if user proceeds

        self.update_status("Refiner LLM (A): Suggestion received.")


    @Slot(tuple)
    def handle_llm_error(self, error_info):
        exctype, value, tb_str = error_info
        print(f"LLM Error: {value}\n{tb_str}")
        self.analysis_browser.setPlaceholderText(f"Error generating refinement: {value}")
        self.show_error("LLM Error", f"Failed to get response from Refiner LLM (A):\n{value}\n\nCheck console log.")
        self.update_status(f"Error: {value}")


    @Slot()
    def on_worker_finished(self):
        self.set_buttons_enabled(True) # Re-enable buttons
        # Disable action buttons if suggestion wasn't found
        if "not found" in self.suggested_prompt.lower():
             self.test_refined_button.setEnabled(False)
             self.accept_suggested_button.setEnabled(False)
             self.update_status("Refiner LLM (A): Failed to extract suggestion.")
        else:
             self.update_status("Ready for next step.")
        self.worker = None

    def test_refined_prompt(self):
        if not self.suggested_prompt or "not found" in self.suggested_prompt.lower():
             self.show_error("Cannot Proceed", "No valid suggested prompt was generated.")
             return

        # Save the current guidance to state before leaving
        self.state_manager.set_optional_guidance(self.guidance_edit.toPlainText())
        self.leave_screen() # Saves state

        # --- Record history of the *previous* attempt before updating prompt ---
        state = self.state_manager.get_state()
        history_entry = {
            "prompt": state.get("currentSystemPrompt"), # The one just tested
            "testerOutput": state.get("lastTesterOutput"),
            "score": state.get("lastScore"),
            "userFeedback": self.guidance_edit.toPlainText().strip(), # Include the guidance that led to this suggestion
            "refinerAnalysis": self.analysis_browser.toPlainText().split("--- Suggested New System Prompt ---")[0].replace("--- Analysis ---", "").strip() # Store analysis
        }
        self.state_manager.add_prompt_history_entry(history_entry)
        # --- End History Recording ---

        # Update the current prompt to the suggested one
        self.state_manager.set_current_prompt(self.suggested_prompt)

        # Navigate back to testing screen to test the new prompt
        self.main_window.navigate_to("output_testing")

    def accept_suggested_prompt(self):
        if not self.suggested_prompt or "not found" in self.suggested_prompt.lower():
             self.show_error("Cannot Proceed", "No valid suggested prompt was generated.")
             return

        final_prompt = self.suggested_prompt
        self.state_manager.set_final_prompt(final_prompt)
        # Save the current guidance to state before leaving
        self.state_manager.set_optional_guidance(self.guidance_edit.toPlainText())
        self.leave_screen() # Saves state

         # --- Record history of the *previous* attempt ---
        state = self.state_manager.get_state()
        history_entry = {
            "prompt": state.get("currentSystemPrompt"), # The one just tested
            "testerOutput": state.get("lastTesterOutput"),
            "score": state.get("lastScore"),
            "userFeedback": self.guidance_edit.toPlainText().strip(),
            "refinerAnalysis": self.analysis_browser.toPlainText().split("--- Suggested New System Prompt ---")[0].replace("--- Analysis ---", "").strip() # Store analysis
        }
        self.state_manager.add_prompt_history_entry(history_entry)
         # --- Add final accepted step to history ---
        final_history_entry = {
             "prompt": final_prompt,
             "testerOutput": "N/A (Accepted suggestion)",
             "score": state.get("lastScore"), # Carry over score? Or mark as accepted?
             "userFeedback": "N/A (Accepted suggestion)",
             "refinerAnalysis": self.analysis_browser.toPlainText().split("--- Suggested New System Prompt ---")[0].replace("--- Analysis ---", "").strip() # Analysis that led to it
        }
        self.state_manager.add_prompt_history_entry(final_history_entry)


        self.main_window.navigate_to("final_prompt")